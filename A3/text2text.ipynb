{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbac605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Global Variables\n",
    "unique_characters = '0123456789+- ' # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)\n",
    "highest_integer = 199 # Highest value of integers contained in the queries\n",
    "max_int_length = len(str(highest_integer)) # \n",
    "max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])\n",
    "max_answer_length = max_int_length + 1    # Maximum length of the answer string\n",
    "\n",
    "# Savefiles\n",
    "queryfile = 'queries_nmax={}.npz'.format(highest_integer)\n",
    "\n",
    "# Model testing\n",
    "gibberish = [\n",
    "    '1  -1  ', '1  - 1 ', '1  -  1', ' 1 -1  ', ' 1 - 1 ', ' 1 -  1', '  1-1  ', '  1- 1 ', '  1-  1',\n",
    "    '1  +1  ', '1  + 1 ', '1  +  1', ' 1 +1  ', ' 1 + 1 ', ' 1 +  1', '  1+1  ', '  1+ 1 ', '  1+  1',\n",
    "    '100-100', '100- 10', '100-  1', ' 10-100', ' 10- 10', ' 10-  1', '  1-100', '  1- 10', '  1-  1',\n",
    "    '100+100', '100+ 10', '100+  1', ' 10+100', ' 10+ 10', ' 10+  1', '  1+100', '  1+ 10', '  1+  1',\n",
    "    ]\n",
    "test_set_sizes = np.arange(1, 10) * 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63e64ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_train_set_size_text2text(X, y):\n",
    "    histories = []\n",
    "    test_set_sizes = np.arange(1, 10) * 0.1\n",
    "    for ratio in test_set_sizes:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            random_state=13,\n",
    "            shuffle=True,\n",
    "            train_size=ratio,\n",
    "            )\n",
    "        text2text = setup_text2text_RNN()\n",
    "        hist = text2text.fit(\n",
    "            x=X_train, y=y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=10,\n",
    "            verbose=1,\n",
    "            )\n",
    "        text2text.save('keras_models/text2text_testsize={:.2f}'.format(ratio))\n",
    "        histories.append(pd.DataFrame.from_dict(hist.history))\n",
    "    return histories\n",
    "\n",
    "def plot_training_history(histories):\n",
    "    df = pd.concat(histories, axis=1, keys=test_set_sizes)\n",
    "    df.columns = df.columns.swaplevel()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    df['loss'].plot(ax=ax, legend=False)\n",
    "    df['val_loss'].plot(ax=ax, linestyle='--', legend=False)\n",
    "    ax.set_xlabel(\"Training Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"images/loss_maxint={}.png\".format(highest_integer), \n",
    "        dpi=300\n",
    "        )\n",
    "    plt.close()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    df['accuracy'].plot(ax=ax, legend=False)\n",
    "    df['val_accuracy'].plot(ax=ax, linestyle='--', legend=False)\n",
    "    ax.set_xlabel(\"Training Epoch\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.legend(bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        \"images/accuracy_maxint={}.png\".format(highest_integer),\n",
    "        dpi=300\n",
    "        )\n",
    "\n",
    "def plot_single_training_history(history, fname):\n",
    "    h_df = pd.DataFrame.from_dict(history.history)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = h_df.plot(figsize=(8,5))\n",
    "    ax.set_xlabel(\"Training Epoch\")\n",
    "    ax.set_ylabel(\"Regression Error Measure\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=300)\n",
    "\n",
    "\n",
    "def baseline_prediction(X, y):\n",
    "    y = y.reshape(-1, max_answer_length * len(unique_characters))\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(\n",
    "            input_shape=(max_query_length, len(unique_characters))\n",
    "            ),\n",
    "        tf.keras.layers.Dense(max_answer_length * len(unique_characters))\n",
    "        ])\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    model.summary()\n",
    "    h = model.fit(\n",
    "        x=X, y=y,\n",
    "        epochs=10,\n",
    "        verbose=0,\n",
    "        )\n",
    "    plot_single_training_history(h, 'images/baseline_maxint={}.png'.format(highest_integer))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def setup_text2text_RNN():\n",
    "    # We start by initializing a sequential model\n",
    "    text2text = tf.keras.Sequential()\n",
    "    \"\"\"\n",
    "    Encode the input sequence using an RNN, producing an output of size 256.\n",
    "    In this case the size of our input vectors is [7, 13] as we have queries \n",
    "    of length 7 and 13 unique characters. Each of these 7 elements in the \n",
    "    query will be fed to the network one by one, as shown in the image above \n",
    "    (except with 7 elements).\n",
    "    Hint: In other applications, where your input sequences have a variable \n",
    "    length (e.g. sentences), you would use \n",
    "    input_shape=(None, unique_characters).\n",
    "    \"\"\"\n",
    "    text2text.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            units=256,\n",
    "            input_shape=(max_query_length, len(unique_characters))\n",
    "            )\n",
    "        )\n",
    "    \"\"\"\n",
    "    As the decoder RNN's input, repeatedly provide with the last output of RNN\n",
    "    for each time step. Repeat 4 times as that's the maximum length of the \n",
    "    output (e.g. '  1-199' = '-198') when using 3-digit integers in queries. \n",
    "    In other words, the RNN will always produce 4 characters as its output.\n",
    "    \"\"\"\n",
    "    text2text.add(\n",
    "        tf.keras.layers.RepeatVector(max_answer_length)\n",
    "        )\n",
    "    \"\"\"\n",
    "    By setting return_sequences to True, return not only the last output but\n",
    "    all the outputs so far in the form of (num_samples, timesteps, output_dim).\n",
    "    This is necessary as TimeDistributed in the below expects the first\n",
    "    dimension to be the timesteps.\n",
    "    \"\"\"\n",
    "    text2text.add(\n",
    "        tf.keras.layers.LSTM(\n",
    "            units=128,\n",
    "            return_sequences=True\n",
    "            )\n",
    "        )\n",
    "    \"\"\"\n",
    "    Apply a dense layer to the every temporal slice of an input. For each of\n",
    "    step of the output sequence, decide which character should be chosen.\n",
    "    \"\"\"\n",
    "    text2text.add(\n",
    "        tf.keras.layers.TimeDistributed(\n",
    "            tf.keras.layers.Dense(len(unique_characters), activation='softmax')\n",
    "            )\n",
    "        )\n",
    "    \"\"\"\n",
    "    Next we compile the model using categorical crossentropy as our loss\n",
    "    function.\n",
    "    \"\"\"\n",
    "    text2text.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    text2text.summary()\n",
    "    return text2text\n",
    "\n",
    "def generate_images(cross=False, n=50):\n",
    "    \"\"\"\n",
    "    Creates 'n' images of randm minus and plus signs. First create empty images\n",
    "    then draw either one (minus) or two (plus) lines using 'cv2.line()'\n",
    "    See https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html#cv2.line\n",
    "    Inputs:\n",
    "        cross - If True, draw plus signs, draw minus otherwise\n",
    "        n - number of signs to create\n",
    "    Returns:\n",
    "        A np.ndarray op dim (n, 28, 28) containing n 28x28 images of the \n",
    "        specified sign.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "\n",
    "    x = np.random.randint(12, 16, (n, 2))\n",
    "    y1 = np.random.randint(4, 8, n)\n",
    "    y2 = np.random.randint(20, 24, n)\n",
    "    \n",
    "    blank = np.zeros([n, 28, 28])\n",
    "    for i in range(n):\n",
    "        line = cv2.line(\n",
    "            img=blank[i],\n",
    "            pt1=(y1[i], x[i,0]),\n",
    "            pt2=(y2[i], x[i, 1]),\n",
    "            color=(255,0,0),\n",
    "            thickness=2,\n",
    "            lineType =cv2.LINE_AA\n",
    "            )\n",
    "        if cross:\n",
    "            line = cv2.line(\n",
    "                img=blank[i],\n",
    "                pt1=(x[i,0], y1[i]),\n",
    "                pt2=(x[i, 1], y2[i]),\n",
    "                color=(255,0,0),\n",
    "                thickness=2,\n",
    "                lineType =cv2.LINE_AA\n",
    "                )\n",
    "    return blank\n",
    "\n",
    "def save_generated(images, fname):\n",
    "    for i in range(20):\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(images[i])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=300)\n",
    "\n",
    "def create_data(highest_integer):\n",
    "    \"\"\"\n",
    "    Creates the following data for all pairs of integers up to [highest integer]+[highest_integer]:\n",
    "\n",
    "    @return:\n",
    "    X_text: '151+ 21' -> text query of an arithmetic operation\n",
    "    X_img : Stack of MNIST images corresponding to the query (7 x 28 x 28)\n",
    "    y_text: ' 172' -> answer of the arithmetic text query\n",
    "    y_img :  Stack of MNIST images corresponding to the answer (4 x 28 x 28)\n",
    "\n",
    "    Images for digits are picked randomly from the whole MNIST dataset.\n",
    "    \"\"\"\n",
    "    print(\"Creating Data\")\n",
    "    (MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "    num_indices = [np.where(MNIST_labels==x) for x in range(10)]\n",
    "    num_data = [MNIST_data[inds] for inds in num_indices]\n",
    "    image_mapping = dict(zip(unique_characters[:10], num_data))\n",
    "    image_mapping['-'] = generate_images()\n",
    "    image_mapping['+'] = generate_images(cross=True)\n",
    "    image_mapping[' '] = np.zeros([1, 28, 28])\n",
    "\n",
    "    X_text, X_img, y_text, y_img = [], [], [], []\n",
    "    for i in range(highest_integer + 1):\n",
    "        for j in range(highest_integer + 1):\n",
    "            \n",
    "            i_char = to_padded_chars(i, max_len=max_int_length)\n",
    "            j_char = to_padded_chars(j, max_len=max_int_length)\n",
    "\n",
    "            for sign in ['-', '+']:\n",
    "                query_string = i_char + sign + j_char\n",
    "                query_image = []\n",
    "                for n, char in enumerate(query_string):\n",
    "                    image_set = image_mapping[char]\n",
    "                    index = np.random.randint(0, len(image_set), 1)\n",
    "                    query_image.append(image_set[index].squeeze())\n",
    "\n",
    "                result = eval(query_string)\n",
    "                result_string = to_padded_chars(result, max_len=max_answer_length)\n",
    "                result_image = []\n",
    "                for n, char in enumerate(result_string):\n",
    "                    image_set = image_mapping[char]\n",
    "                    index = np.random.randint(0, len(image_set), 1)\n",
    "                    result_image.append(image_set[index].squeeze())\n",
    "\n",
    "                X_text.append(query_string)\n",
    "                X_img.append(np.stack(query_image))\n",
    "                y_text.append(result_string)\n",
    "                y_img.append(np.stack(result_image))\n",
    "            \n",
    "    return np.stack(X_text), np.stack(X_img)/255., np.stack(y_text), np.stack(y_img)/255.\n",
    "  \n",
    "def to_padded_chars(integer, max_len=3, pad_right=False):\n",
    "    \"\"\"\n",
    "    Returns a string of len()=max_len, containing the integer padded with ' ' on either right or left side\n",
    "    \"\"\"\n",
    "    length = len(str(integer))\n",
    "    padding = (max_len - length) * ' '\n",
    "    if pad_right:\n",
    "        return str(integer) + padding\n",
    "    else:\n",
    "        return padding + str(integer)\n",
    "\n",
    "def display_sample(n, fname):\n",
    "    labs = ['X_img:', 'y_img:']\n",
    "    for i, data in enumerate([X_img, y_img]):\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(labs[i])\n",
    "        plt.imshow(np.hstack(data[n]), cmap='gray')\n",
    "    print('='*50, f'\\nSample ID: {n}\\n\\nX_text: \"{X_text[n]}\" = y_text: \"{y_text[n]}\"')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=300)\n",
    "\n",
    "def encode_labels(labels, max_len=4):\n",
    "    n = len(labels)\n",
    "    length = len(labels[0])\n",
    "    char_map = dict(zip(unique_characters, range(len(unique_characters))))\n",
    "    one_hot = np.zeros([n, length, len(unique_characters)])\n",
    "    for i, label in enumerate(labels):\n",
    "        m = np.zeros([length, len(unique_characters)])\n",
    "        for j, char in enumerate(label):\n",
    "            m[j, char_map[char]] = 1\n",
    "        one_hot[i] = m\n",
    "\n",
    "    return one_hot \n",
    "\n",
    "def decode_labels(labels):\n",
    "    pred = np.argmax(labels, axis=2)\n",
    "    decoded_predictions = []\n",
    "    for pred_i in pred:\n",
    "        seq = ''.join([unique_characters[i] for i in pred_i])\n",
    "        decoded_predictions.append(seq)\n",
    "    return np.array(decoded_predictions)\n",
    "\n",
    "def load_query_data(txt_x=True, txt_y=True):\n",
    "    try:\n",
    "        with open(queryfile, 'rb') as f:\n",
    "            data = np.load(f)\n",
    "            X_text = data['arr_0']\n",
    "            X_img = data['arr_1']\n",
    "            y_text = data['arr_2']\n",
    "            y_img = data['arr_3']\n",
    "    except:\n",
    "        X_text, X_img, y_text, y_img = create_data(highest_integer)\n",
    "        with open(queryfile, 'wb') as f:\n",
    "            np.savez(f, X_text, X_img, y_text, y_img)\n",
    "    if txt_x and txt_y:\n",
    "        return X_text, y_text\n",
    "    elif txt_x and not txt_y:\n",
    "        return X_text, flatten(y_img)\n",
    "    elif not txt_x and txt_y:\n",
    "        return flatten(X_img), y_text\n",
    "    elif not txt_x and not txt_y:\n",
    "        return flatten(X_img), flatten(y_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8411df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text, y_text = load_query_data()\n",
    "X_text_onehot = encode_labels(X_text)\n",
    "y_text_onehot = encode_labels(y_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efa45d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               276480    \n",
      "                                                                 \n",
      " repeat_vector (RepeatVector  (None, 4, 256)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 4, 128)            197120    \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 4, 13)            1677      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 475,277\n",
      "Trainable params: 475,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 1.6385 - accuracy: 0.3923"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_796/3536627983.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_best_train_set_size_text2text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_text_onehot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_text_onehot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_796/3081128807.py\u001b[0m in \u001b[0;36mfind_best_train_set_size_text2text\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     10\u001b[0m             )\n\u001b[0;32m     11\u001b[0m         \u001b[0mtext2text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup_text2text_RNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         hist = text2text.fit(\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1252\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1537\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histories = find_best_train_set_size_text2text(X_text_onehot, y_text_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7677b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_RMSE_of_model_predictions(text2textmodel, num_predictions):\n",
    "    choice = np.random.randint(0, len(X_text), size=num_predictions)\n",
    "    entries=X_text[choice]\n",
    "    true_answers = y_text[choice]\n",
    "    hot_answers = text2textmodel.predict(encode_labels(entries))\n",
    "    answers = decode_labels(hot_answers)\n",
    "    try:\n",
    "        answers = answers.astype(int)\n",
    "    except:\n",
    "        answers = remove_invalid_answers(answers)\n",
    "    true_answers = true_answers.astype(int)\n",
    "    RMSE = np.sqrt(np.mean((answers - true_answers)**2))\n",
    "    print(\"RMSE: {:.2f}\".format(RMSE))\n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba38b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_invalid_answers(prediction):\n",
    "    answer = np.zeros(prediction.shape)\n",
    "    num_invalid = 0\n",
    "    for i, p in enumerate(prediction):\n",
    "        try:\n",
    "            answer[i] = int(p)\n",
    "        except:\n",
    "            answer[i] = 0\n",
    "            num_invalid += 1\n",
    "    print(\"Found {} invalid predictions.\".format(num_invalid))\n",
    "    return answer\n",
    "\n",
    "def test_model_intuition(text2textmodel):\n",
    "    hot_gibberish = encode_labels(gibberish)\n",
    "    hot_predict = text2textmodel.predict(hot_gibberish)\n",
    "    predict = decode_labels(hot_predict)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb65666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with test size: 0.1\n",
      "RMSE: 20.53\n",
      "Model with test size: 0.2\n",
      "RMSE: 7.74\n",
      "Model with test size: 0.3\n",
      "RMSE: 5.68\n",
      "Model with test size: 0.4\n",
      "RMSE: 6.63\n",
      "Model with test size: 0.5\n",
      "RMSE: 11.03\n",
      "Model with test size: 0.6\n",
      "Found 8 invalid predictions.\n",
      "RMSE: 6.87\n",
      "Model with test size: 0.7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_796/2621451382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mratio\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_set_sizes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model with test size: {:.1f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     model = tf.keras.models.load_model(\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;34m'keras_models/text2text_testsize={:.2f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     )\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    212\u001b[0m                 \u001b[1;34m'Filepath looks like a hdf5 file but h5py is not available.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m                 f' filepath={filepath}')\n\u001b[1;32m--> 214\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m   raise IOError(\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    140\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaded_node\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeras_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloaded_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[0mnodes_to_load\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m   loaded = tf.__internal__.saved_model.load_partial(\n\u001b[0m\u001b[0;32m    143\u001b[0m       path, nodes_to_load, options=options)\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    804\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0mnode\u001b[0m \u001b[0mpaths\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfilter\u001b[0m \u001b[0mto\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m   \"\"\"\n\u001b[1;32m--> 806\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 938\u001b[1;33m         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0m\u001b[0;32m    939\u001b[0m                             ckpt_options, options, filters)\n\u001b[0;32m    940\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msave_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_skip_checkpoint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCapturableResource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[0mload_status\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_nontrivial_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mload_status\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariables_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[0mload_status\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_existing_objects_matched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_status\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1364\u001b[0m         \u001b[0mgraph_view\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m         options=options)\n\u001b[1;32m-> 1366\u001b[1;33m     base.CheckpointPosition(\n\u001b[0m\u001b[0;32m   1367\u001b[0m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[0;32m   1368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    973\u001b[0m       \u001b[0mcurrent_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvisit_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m       new_restore_ops, new_tensor_saveables, new_python_saveables = (\n\u001b[1;32m--> 975\u001b[1;33m           \u001b[0mcurrent_position\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrackable\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m           ._single_restoration_from_checkpoint_position(\n\u001b[0;32m    977\u001b[0m               \u001b[0mcheckpoint_position\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_single_restoration_from_checkpoint_position\u001b[1;34m(self, checkpoint_position, visit_queue)\u001b[0m\n\u001b[0;32m   1011\u001b[0m                                                []).append(child_position)\n\u001b[0;32m   1012\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mchild_position\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlocal_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m           \u001b[1;31m# This object's correspondence is new, so dependencies need to be\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m           \u001b[1;31m# visited. Delay doing it so that we get a breadth-first dependency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mbind_object\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;31m# method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_object\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_create_or_restore_slot_variable\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m           optimizer_object._create_or_restore_slot_variable(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    304\u001b[0m               slot_variable_position=CheckpointPosition(\n\u001b[0;32m    305\u001b[0m                   \u001b[0mcheckpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_create_or_restore_slot_variable\u001b[1;34m(self, slot_variable_position, slot_name, variable)\u001b[0m\n\u001b[0;32m   1405\u001b[0m       \u001b[1;31m# If we've either made this slot variable, or if we've pulled out an\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m       \u001b[1;31m# existing slot variable, we should restore it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m       \u001b[0mslot_variable_position\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslot_variable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1408\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m       \u001b[1;31m# We didn't make the slot variable. Defer restoring until it gets created\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, trackable)\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[1;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[1;34m(self, checkpoint_position)\u001b[0m\n\u001b[0;32m    981\u001b[0m       \u001b[0mpython_saveables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_python_saveables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m     restore_ops.extend(\n\u001b[1;32m--> 983\u001b[1;33m         current_position.checkpoint.restore_saveables(\n\u001b[0m\u001b[0;32m    984\u001b[0m             tensor_saveables, python_saveables))\n\u001b[0;32m    985\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore_saveables\u001b[1;34m(self, tensor_saveables, python_saveables)\u001b[0m\n\u001b[0;32m    327\u001b[0m             (\"Saveable keys changed when validating. Got back %s, was \"\n\u001b[0;32m    328\u001b[0m              \"expecting %s\") % (tensor_saveables.keys(), validated_names))\n\u001b[1;32m--> 329\u001b[1;33m       new_restore_ops = functional_saver.MultiDeviceSaver(\n\u001b[0m\u001b[0;32m    330\u001b[0m           validated_saveables).restore(self.save_path_tensor, self.options)\n\u001b[0;32m    331\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    337\u001b[0m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_function_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m       \u001b[0mrestore_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_after_restore_callbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    321\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_single_device_savers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m           \u001b[0mrestore_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mrestore_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_io_device\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestore_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       restored_tensors = io_ops.restore_v2(\n\u001b[0m\u001b[0;32m    109\u001b[0m           file_prefix, tensor_names, tensor_slices, tensor_dtypes)\n\u001b[0;32m    110\u001b[0m     structured_restored_tensors = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, dtypes, name)\u001b[0m\n\u001b[0;32m   1487\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m       return restore_v2_eager_fallback(\n\u001b[0m\u001b[0;32m   1490\u001b[0m           \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m           ctx=_ctx)\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mrestore_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, dtypes, name, ctx)\u001b[0m\n\u001b[0;32m   1526\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1527\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"dtypes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1528\u001b[1;33m   _result = _execute.execute(b\"RestoreV2\", len(dtypes), inputs=_inputs_flat,\n\u001b[0m\u001b[0;32m   1529\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0;32m   1530\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\venv\\IDL\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RMSEs = []\n",
    "predictions = []\n",
    "for ratio in test_set_sizes:\n",
    "    print(\"Model with test size: {:.1f}\".format(ratio))\n",
    "    model = tf.keras.models.load_model(\n",
    "        'keras_models/text2text_testsize={:.2f}'.format(ratio)\n",
    "    )\n",
    "    RMSEs.append(calc_RMSE_of_model_predictions(model, 1000))\n",
    "    predictions.append(test_model_intuition(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotted_gibberish = [gib.replace(' ', '.') for gib in gibberish]\n",
    "pred_df = pd.DataFrame(predictions, index=test_set_sizes, columns=dotted_gibberish)\n",
    "pred_df= pred_df.transpose()\n",
    "with open('predictions.tex', 'w') as f:\n",
    "    pred_df.to_latex(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ad5e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
